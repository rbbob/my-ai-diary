import { useState, useEffect, useRef } from 'react';

const useSpeechRecognition = () => {
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [isSupported, setIsSupported] = useState(false);
  const [error, setError] = useState(null);
  
  const recognitionRef = useRef(null);
  const timeoutRef = useRef(null);

  useEffect(() => {
    // Web Speech APIå¯¾å¿œãƒã‚§ãƒƒã‚¯
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (SpeechRecognition) {
      setIsSupported(true);
      recognitionRef.current = new SpeechRecognition();
      
      // åŸºæœ¬è¨­å®š
      recognitionRef.current.lang = 'ja-JP';
      recognitionRef.current.continuous = true;
      recognitionRef.current.interimResults = true;
      recognitionRef.current.maxAlternatives = 1;

      // ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼è¨­å®š
      recognitionRef.current.onstart = () => {
        console.log('ðŸŽ¤ éŸ³å£°èªè­˜é–‹å§‹');
        setIsRecording(true);
        setError(null);
      };

      recognitionRef.current.onresult = (event) => {
        let finalTranscript = '';
        let interimTranscript = '';

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcriptPart = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcriptPart;
          } else {
            interimTranscript += transcriptPart;
          }
        }

        // æœ€çµ‚çµæžœã¾ãŸã¯ä¸­é–“çµæžœã‚’è¨­å®š
        const fullTranscript = finalTranscript || interimTranscript;
        setTranscript(fullTranscript);

        // 3ç§’é–“ç„¡éŸ³ãŒç¶šã„ãŸã‚‰è‡ªå‹•åœæ­¢
        if (timeoutRef.current) {
          clearTimeout(timeoutRef.current);
        }
        timeoutRef.current = setTimeout(() => {
          if (recognitionRef.current && isRecording) {
            recognitionRef.current.stop();
          }
        }, 3000);
      };

      recognitionRef.current.onend = () => {
        console.log('ðŸ”‡ éŸ³å£°èªè­˜çµ‚äº†');
        setIsRecording(false);
        if (timeoutRef.current) {
          clearTimeout(timeoutRef.current);
        }
      };

      recognitionRef.current.onerror = (event) => {
        console.error('ðŸš¨ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:', event.error);
        setIsRecording(false);
        setError(getErrorMessage(event.error));
        if (timeoutRef.current) {
          clearTimeout(timeoutRef.current);
        }
      };
    }

    return () => {
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
      }
    };
  }, [isRecording]);

  const getErrorMessage = (errorType) => {
    switch (errorType) {
      case 'not-allowed':
        return 'ãƒžã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã§ãƒžã‚¤ã‚¯ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚';
      case 'no-speech':
        return 'éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚';
      case 'audio-capture':
        return 'ãƒžã‚¤ã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚ãƒžã‚¤ã‚¯ãŒæŽ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚';
      case 'network':
        return 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæŽ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚';
      case 'aborted':
        return 'éŸ³å£°èªè­˜ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚';
      default:
        return `éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: ${errorType}`;
    }
  };

  const startRecording = async () => {
    if (!isSupported) {
      setError('ãŠä½¿ã„ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚Chromeã€Edgeã€Safariã‚’ãŠè©¦ã—ãã ã•ã„ã€‚');
      return;
    }

    if (isRecording) {
      return;
    }

    try {
      // ãƒžã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
      await navigator.mediaDevices.getUserMedia({ audio: true });
      
      setTranscript('');
      setError(null);
      recognitionRef.current.start();
    } catch (err) {
      console.error('ãƒžã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼:', err);
      setError('ãƒžã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã§ãƒžã‚¤ã‚¯ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚');
    }
  };

  const stopRecording = () => {
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
        setIsRecording(false); // ç¢ºå®Ÿã«åœæ­¢çŠ¶æ…‹ã«ã™ã‚‹
        if (timeoutRef.current) {
          clearTimeout(timeoutRef.current);
        }
      } catch (error) {
        console.error('åœæ­¢ã‚¨ãƒ©ãƒ¼:', error);
        setIsRecording(false); // ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚åœæ­¢çŠ¶æ…‹ã«ã™ã‚‹
      }
    }
  };

  const resetTranscript = () => {
    setTranscript('');
    setError(null);
  };

  return {
    transcript,
    isRecording,
    isSupported,
    error,
    startRecording,
    stopRecording,
    resetTranscript
  };
};

export default useSpeechRecognition;